{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7iReAywmZzrVqQWuactak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranav-Bhatlapenumarthi/Data-Preprocessing-Air-Quality-Analyisis/blob/main/Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing for Air Quality Analysis\n",
        "\n",
        "Disclaimer: The original .xlsx file has be renamed and has been converted to a .csv file.\n",
        "\n",
        "Please run the entire notebook to get final results."
      ],
      "metadata": {
        "id": "xgeGWkvOz9HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "WM_sopEmu8Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling Missing Values\n",
        "\n",
        "Given that entries tagged as \"-200\" are missing values.\n",
        "\n",
        "Step 1: Locate the missing values\n",
        "\n",
        "Step 2: Replace the \"-200\" entries with null values\n",
        "\n",
        "Step 3: Replace the null entries with the mean value the column. This ensures consistency in the range of all the values in the column."
      ],
      "metadata": {
        "id": "zR2Cc5OH0Zu_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7U8V5e0z3hR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/AirQualityUCI.csv - AirQualityUCI.csv\") #Loading the CSV file\n",
        "missing_val = (df == -200).sum()\n",
        "print(missing_val) #Locating the number of missing values in each column\n",
        "\n",
        "df.replace(-200, np.nan, inplace = True) # Replacing missing values with NA in the original file. This helps accurate calculation of the mean\n",
        "df.fillna(df.mean(numeric_only=True), inplace = True) # Replacing the NA values with the mean in numeric valued columns\n",
        "\n",
        "new_missing_val = (df == np.nan).sum() # Checking if any null values still exist after updation\n",
        "print(new_missing_val) # Printing out the number of missing values after updation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analysing the data(a little bit...)\n",
        "\n",
        "We first need to get a sense of how the data looks like. This information(such as skewness of the data) will help us decide on what methods to apply for further preprocessing"
      ],
      "metadata": {
        "id": "oTcJFsTsiKOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_headers = ['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)',\n",
        "       'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n",
        "       'PT08.S5(O3)', 'T', 'RH', 'AH'] # Features of interest\n",
        "\n",
        "for feature in data_headers:\n",
        "  print(feature)\n",
        "  print(\"Mean: \", df[feature].mean(), \", Min: \", df[feature].min(), \", Max: \", df[feature].max())"
      ],
      "metadata": {
        "id": "VLBz8IjFiJ9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outlier Detection and Handling\n",
        "This is a crucial part of data preprocessing as it detects any significantly varying values in the dataset which may adversly affect the functioning of the Machine Learning model to make predictions.\n",
        "\n",
        "In the given dataset, the entries are clearly skewed(non-symmetric). Hence we use IQR(Interquartile Range) method to detect the outliers.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GcGV8GkGeVqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_outliers(df, columns):\n",
        "  outliers = {}\n",
        "\n",
        "  for col in columns:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    outlier_indices = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index.tolist()\n",
        "    outliers[col] = outlier_indices\n",
        "\n",
        "  return outliers\n",
        "\n",
        "outliers = detect_outliers(df, data_headers)\n",
        "for k in outliers:\n",
        "  print(k,outliers[k])\n"
      ],
      "metadata": {
        "id": "0QsTP8Y_eVaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Feature Scaling\n",
        "Feature scaling is a process of standardisation of numerical features to have a uniform range across all features.\n",
        "\n",
        "For the given dataset, Min-Max Scaling is used since it is easier to interpret (since the range is between 0 and 1) and the units are not varying too much."
      ],
      "metadata": {
        "id": "m2U9oxCd0c-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns) #To check all the feature headings\n",
        "toScale = ['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)',\n",
        "       'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n",
        "       'PT08.S5(O3)', 'T', 'RH', 'AH']\n",
        "\n",
        "scaler = MinMaxScaler() #Initialising the scaler\n",
        "df[toScale] = scaler.fit_transform(df[toScale]) #Scaling only selected features\n",
        "df.head() #Checking the current status of the dataset"
      ],
      "metadata": {
        "id": "nF1FKb_M0cqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "OQlTSCavw9By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#print(df.head(50)) # Displays first 50 records\n",
        "df.describe() # To give overall summary statistics\n",
        "selected_features = ['CO(GT)', 'PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)',\n",
        "       'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)',\n",
        "       'PT08.S5(O3)', 'T', 'RH', 'AH']\n",
        "\n",
        "df_copy = df[selected_features].copy()\n",
        "plt.figure(figsize = (16,10))\n",
        "sns.heatmap(df_copy.corr(), cmap=\"RdBu\",annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "abED4oqAw8wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features to visualize\n",
        "selected_features = [\"CO(GT)\", \"NOx(GT)\", \"T\", \"RH\", \"PT08.S1(CO)\"]\n",
        "\n",
        "# Create scatter plots\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, feature in enumerate(selected_features):\n",
        "    plt.subplot(2, len(selected_features) // 2 + 1, i + 1)\n",
        "    sns.scatterplot(x=df.index, y=df[feature])\n",
        "    plt.title(f\"Scatterplot of {feature}\")\n",
        "    plt.xlabel(\"Index\")\n",
        "    plt.ylabel(feature)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hoJQ65tl1EFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis\n",
        "\n",
        "CO(GT) Scatterplot:\n",
        "\n",
        "\n",
        "\n",
        "*   The concentration spikes at multiple points, indicating potential pollution events.\n",
        "*   There seems to be a periodic pattern, with values fluctuating significantly.\n",
        "\n",
        "NOx(GT) Scatterplot:\n",
        "\n",
        "*  The trend follows a similar structure as CO(GT), with increased values in specific regions.\n",
        "* There is a cluster of low values, which might indicate sensor inaccuracies or missing values.\n",
        "T (Temperature) Scatterplot:\n",
        "\n",
        "PT08.S1(CO) Scatterplot:\n",
        "\n",
        "* The pattern resembles CO(GT), which aligns with its high correlation in the heatmap.\n",
        "* The values fluctuate widely, possibly due to pollution events or measurement variations.\n",
        "\n",
        "Key Takeaways:\n",
        "1. Cyclic or Seasonal Trends: The features T and RH display cyclic\n",
        "patterns, suggesting periodic environmental changes.\n",
        "2. High Correlation Features: The scatter plots for CO(GT) and PT08.S1(CO) suggest a direct relationship (also supported by the heatmap).\n",
        "3. Potential Data Issues: Some plots show horizontal bands, which might indicate few sensor errors"
      ],
      "metadata": {
        "id": "qOS73gVA1xOp"
      }
    }
  ]
}